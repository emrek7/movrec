{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.5681767463684 seconds to download 350 usernames.\n"
     ]
    }
   ],
   "source": [
    "BASE_PEOPLE = \"https://letterboxd.com/people/popular/page/\"\n",
    "LBOX = \"https://letterboxd.com\"\n",
    "REV = \"films/reviews/page/\"\n",
    "\n",
    "userNames = list()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get the usernames from people page by all-time popularity (set to: 1st page)\n",
    "for i in range (11,21):\n",
    "    URL = BASE_PEOPLE + str(i)\n",
    "    req = urllib.request.Request(URL)\n",
    "    user_agent = UserAgent().random\n",
    "    req.add_header('user-agent', user_agent)\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(req),\"html.parser\")\n",
    "    time.sleep(random.randint(10,15))\n",
    "    for tag in soup.find_all(\"h3\", \"title-3\"):\n",
    "        href = tag.a.get(\"href\")\n",
    "        userNames.append(href)\n",
    "    \n",
    "t1 = time.time()            \n",
    "print(f\"{t1-t0} seconds to download {len(userNames)} usernames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing most popular userNames (the ones on the right dock)\n",
    "userNames = [user for user in userNames if user not in ['/bratpitt/', '/deathproof/', '/davidehrlich/', '/adrianbalboa/','/silentdawn/'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "driver = webdriver.Chrome('chromedriver.exe')  #using Selenium-Chrome simulator to interact with JS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store num. of pages of reviews to usernames\n",
    "numPageReviews = dict()\n",
    "\n",
    "# driver = webdriver.Chrome(ChromeDriverManager().install()) \n",
    "t0 = time.time()\n",
    "\n",
    "for name in userNames[6:]:\n",
    "    # Find num. of pages of reviews from the first page\n",
    "    firstPage = LBOX + name + REV + \"1\"\n",
    "    \n",
    "    req = urllib.request.Request(firstPage)\n",
    "    user_agent = UserAgent().random\n",
    "    req.add_header('user-agent', user_agent)\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(req),\"html.parser\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Store user's all review data (movie/film name + year + review + rating)\n",
    "    data = list()\n",
    "    \n",
    "    pageFooter = soup.find_all(\"div\", \"paginate-pages\")\n",
    "    if len(pageFooter) == 0:\n",
    "        numPageReviews[name] = 1;\n",
    "    else:\n",
    "        item = soup.find_all('li','paginate-page')\n",
    "        numPageReviews[name] = (int(item[-1].text))\n",
    "    \n",
    "    # Initialize lists for data\n",
    "    ratings = list()\n",
    "    movies = list()\n",
    "    relYears = list()\n",
    "    reviews = list()\n",
    "    dates = list()\n",
    "    reWatch = list()\n",
    "    numRevLikes = list()\n",
    "    \n",
    "    # Loop through all pages and obtain data from each page\n",
    "    for pageNum in range(1, numPageReviews[name]+1):\n",
    "        thePage = LBOX + name + REV + str(pageNum)\n",
    "        options = Options()\n",
    "        user_agent = UserAgent().random\n",
    "        options.add_argument(f'user-agent={user_agent}')\n",
    "        driver = webdriver.Chrome('chromedriver.exe', options=options)\n",
    "        driver.maximize_window()\n",
    "        driver.get(thePage)\n",
    "        time.sleep(random.randint(10,20))\n",
    "        # Click on the spoilers links\n",
    "        spoilers = list()\n",
    "        spoilers = driver.find_elements_by_link_text('I can handle the truth.')\n",
    "        state = True\n",
    "        if len(spoilers)==0:\n",
    "            state = False   \n",
    "        if state ==True:\n",
    "            for i in range(len(spoilers)):\n",
    "                time.sleep(7)\n",
    "                attempts = 0\n",
    "                while(attempts < 2):\n",
    "                    try:\n",
    "                        WebDriverWait(driver,20).until(EC.element_to_be_clickable((By.LINK_TEXT,'I can handle the truth.'))).click()\n",
    "                        break\n",
    "                    except TimeoutException:\n",
    "                        print(name + \": TimeoutException Error  at :\" + thePage + \" at entry: \" + str(i))\n",
    "                    except ElementNotInteractableException:\n",
    "                        print(name + \": ElementNotInteractableException Error  at :\" + thePage + \" at entry: \" + str(i))\n",
    "                    except StaleElementReferenceException:\n",
    "                        print(name + \": StaleElementReferenceException Error  at :\" + thePage + \" at entry: \" + str(i))\n",
    "                    attempts += 1\n",
    "        # Click on the \"more\" links to reveal all text            \n",
    "        linksMore = list()\n",
    "        time.sleep(7)\n",
    "        linksMore = driver.find_elements_by_class_name('reveal')\n",
    "        state = True\n",
    "        if len(linksMore)==0:\n",
    "            state = False   \n",
    "        if state == True:\n",
    "            for i in range(len(linksMore)):\n",
    "                time.sleep(5)\n",
    "                attempts = 0\n",
    "                while(attempts < 2):\n",
    "                    try:\n",
    "                        WebDriverWait(driver,20).until(EC.element_to_be_clickable((By.CLASS_NAME,'reveal'))).click()\n",
    "                        break\n",
    "                    except TimeoutException:\n",
    "                        print(name + \": TimeoutException Error  at :\" + thePage + \" at entry: \" + str(i))\n",
    "                    except ElementNotInteractableException:\n",
    "                        print(name + \": ElementNotInteractableException Error  at :\" + thePage + \" at entry: \" + str(i))\n",
    "                    except StaleElementReferenceException:\n",
    "                        print(name + \": StaleElementReferenceException Error  at :\" + thePage + \" at entry: \" + str(i))\n",
    "                    attempts += 1\n",
    "        \n",
    "        time.sleep(7)\n",
    "        soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "        \n",
    "        ratingList = list()  # list to store the review entries with ratings only      \n",
    "        for tag in soup.find_all(\"p\", \"attribution\"):\n",
    "            spans = tag.find_all('span','rating')\n",
    "            ratingList.append(spans)\n",
    "            for span in spans:\n",
    "                rating = [i for i in str(span.attrs.get('class')) if i in \"0123456789\"]\n",
    "                if len(rating)==2:\n",
    "                    rating = ['10']\n",
    "                ratings.append(rating[0])\n",
    "\n",
    "        for i, tag in enumerate(soup.find_all(\"h2\", \"headline-2 prettify\")):\n",
    "            if not ratingList[i]:\n",
    "                continue\n",
    "            filmName = tag.a.text\n",
    "            filmYear = tag.small.a.text if tag.small else '0'\n",
    "            movies.append(filmName)\n",
    "            relYears.append(filmYear)\n",
    "        \n",
    "\n",
    "        for i, tag in enumerate(soup.find_all(\"div\", \"body-text\")):\n",
    "            if not ratingList[i]:\n",
    "                continue\n",
    "            rev = \"\"\n",
    "            for item in tag:\n",
    "                if isinstance(item, NavigableString):\n",
    "                    continue\n",
    "                rev += str(item.text)\n",
    "            reviews.append(cleanhtml(rev))\n",
    "            \n",
    "        for i, tag in enumerate(soup.find_all(\"span\",\"_nobr\")):\n",
    "            if not ratingList[i]:\n",
    "                continue\n",
    "            dates.append(tag.text)\n",
    "        \n",
    "        for i, tag in enumerate(soup.find_all(\"span\",\"date\")):\n",
    "            if not ratingList[i]:\n",
    "                continue\n",
    "            if tag.text.startswith(\" R\"):\n",
    "                reWatch.append(1)\n",
    "            else:\n",
    "                reWatch.append(0)\n",
    "        \n",
    "        for i, tag in enumerate(soup.find_all(\"p\", \"like-link-target\")):\n",
    "            if not ratingList[i]:\n",
    "                continue\n",
    "            if tag.span:\n",
    "                numLike = ''.join([i for i in tag.span.a.text if i in \"0123456789\"])\n",
    "            else:\n",
    "                numLike = '0'\n",
    "            numRevLikes.append(numLike)\n",
    "        \n",
    "        driver.quit()\n",
    "            \n",
    "    for i in range(len(ratings)):\n",
    "        data.append([name, movies[i], relYears[i], reviews[i], ratings[i], dates[i], reWatch[i], numRevLikes[i]])\n",
    "        \n",
    "    df = pd.DataFrame(data, columns = ['userName' , 'filmName', 'releaseYear', 'userReview','userRating', 'reviewDate','reWatched',\n",
    "                                       'reviewLikes'])\n",
    "    df[['releaseYear','userRating','reWatched','reviewLikes']] = df[['releaseYear','userRating','reWatched','reviewLikes']].apply(pd.to_numeric, downcast='integer')\n",
    "    \n",
    "    df.to_csv(\"movrec.tsv\", sep='\\t', index=False, columns=None, header=False, mode='a')\n",
    "    \n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_table(\"movrec.tsv\", names=['userName' , 'filmName', 'releaseYear', 'userReview','userRating', 'reviewDate','reWatched','reviewLikes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/worsethan/', '/justwannaboogie/', '/owene73/', '/valdesbian/',\n",
       "       '/ashmatxx/'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.userName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>filmName</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>userReview</th>\n",
       "      <th>userRating</th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>reWatched</th>\n",
       "      <th>reviewLikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>/ashmatxx/</td>\n",
       "      <td>Love, Simon</td>\n",
       "      <td>2018</td>\n",
       "      <td>I'm so super glad that this film is doing posi...</td>\n",
       "      <td>4</td>\n",
       "      <td>22 Oct, 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5855</th>\n",
       "      <td>/ashmatxx/</td>\n",
       "      <td>The Tale</td>\n",
       "      <td>2018</td>\n",
       "      <td>This film really took its time getting me inve...</td>\n",
       "      <td>7</td>\n",
       "      <td>22 Oct, 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>/ashmatxx/</td>\n",
       "      <td>The Kissing Booth</td>\n",
       "      <td>2018</td>\n",
       "      <td>Don’t know what else I expected from a film I ...</td>\n",
       "      <td>3</td>\n",
       "      <td>22 Oct, 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>/ashmatxx/</td>\n",
       "      <td>John Mulaney: Kid Gorgeous at Radio City</td>\n",
       "      <td>2018</td>\n",
       "      <td>I had never seen my partner cry with laughter ...</td>\n",
       "      <td>8</td>\n",
       "      <td>22 Oct, 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>/ashmatxx/</td>\n",
       "      <td>Set It Up</td>\n",
       "      <td>2018</td>\n",
       "      <td>If you want to watch something while you’re no...</td>\n",
       "      <td>5</td>\n",
       "      <td>22 Oct, 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userName                                  filmName  releaseYear  \\\n",
       "5854  /ashmatxx/                               Love, Simon         2018   \n",
       "5855  /ashmatxx/                                  The Tale         2018   \n",
       "5856  /ashmatxx/                         The Kissing Booth         2018   \n",
       "5857  /ashmatxx/  John Mulaney: Kid Gorgeous at Radio City         2018   \n",
       "5858  /ashmatxx/                                 Set It Up         2018   \n",
       "\n",
       "                                             userReview  userRating  \\\n",
       "5854  I'm so super glad that this film is doing posi...           4   \n",
       "5855  This film really took its time getting me inve...           7   \n",
       "5856  Don’t know what else I expected from a film I ...           3   \n",
       "5857  I had never seen my partner cry with laughter ...           8   \n",
       "5858  If you want to watch something while you’re no...           5   \n",
       "\n",
       "        reviewDate  reWatched  reviewLikes  \n",
       "5854  22 Oct, 2018          0            1  \n",
       "5855  22 Oct, 2018          0            0  \n",
       "5856  22 Oct, 2018          0            0  \n",
       "5857  22 Oct, 2018          1            1  \n",
       "5858  22 Oct, 2018          0            0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(userNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
